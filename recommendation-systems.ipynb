{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install contractions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Movie Data file","metadata":{}},{"cell_type":"code","source":"df_movie = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/movie.csv\")\n# df_movie[[\"title\",\"year\"]] = df_movie[\"title\"].str.split(\"(\",expand=True)[[0,1]]\ndf_movie[\"year\"] = df_movie[\"title\"].str[-5:-1]\ndf_movie[\"title\"] = df_movie[\"title\"].str[:-7]\n# df_movie[\"year\"] = df_movie[\"year\"].str.replace(\")\",\"\")\ndf_movie[\"genres\"] = df_movie[\"genres\"].str.replace(\"|\",\" , \")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movie","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Tags Data File","metadata":{}},{"cell_type":"code","source":"df_tags = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/tag.csv\").drop(\"timestamp\",axis=1)\ndf_tags[\"tag\"] = df_tags[\"tag\"].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tags","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tags = df_tags.groupby(\"movieId\")[\"tag\"].apply(lambda x: ' , '.join(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(df_tags,df_movie,on=\"movieId\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Ratings Data File (for avg rating and popularity)","metadata":{}},{"cell_type":"code","source":"df_rating = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/rating.csv\").drop(\"timestamp\",axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_avg_rating = df_rating.groupby(\"movieId\").agg({\"rating\":[\"mean\",\"count\"]}).reset_index()\nmovie_avg_rating.columns = [\"movieId\", \"Avg_Rating\" , \"Popularity\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.merge(df,movie_avg_rating,on=\"movieId\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = df2.sort_values(by= [\"Popularity\",\"Avg_Rating\"],ascending = False)\ndf3 = df3.drop_duplicates(subset=['movieId']).reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting more tags","metadata":{}},{"cell_type":"markdown","source":"#### According to the Genome_tages I am getting 95+% relevance tags","metadata":{}},{"cell_type":"code","source":"df_more_tags = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/genome_scores.csv\")\nmore_tags_data = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/genome_tags.csv\")\ndf_more_tags = pd.merge(df_more_tags,more_tags_data,on=\"tagId\",how=\"left\")\ndf_more_tags = df_more_tags[df_more_tags[\"relevance\"]>=0.95]\nmore_tags = df_more_tags.groupby(\"movieId\")[\"tag\"].apply(lambda x: ' , '.join(x)).reset_index()\nmore_tags.columns = [\"movieId\",\"tag2\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"more_tags","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4 = pd.merge(df3,more_tags,on = \"movieId\",how=\"left\")\ndf4 = df4.fillna(\" \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4[\"Final_Tags\"] = df4[\"tag\"] +\" \"+df4[\"genres\"]+\" \"+df4[\"tag2\"]+\" \"+df4[\"year\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = df4[[\"title\",\"Final_Tags\",\"year\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stripping the tags to 400 strings","metadata":{}},{"cell_type":"code","source":"final_df[\"Final_Tags\"] = final_df[\"Final_Tags\"].str[:400]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build a Movie Recommender System","metadata":{}},{"cell_type":"code","source":"import nltk\nimport re\nimport numpy as np\nimport contractions\n\nstop_words = nltk.corpus.stopwords.words('english')\ndef normalize_document(doc):\n    # lower case and remove special characters\\whitespaces\n    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n    doc = doc.lower()\n    doc = doc.strip()\n    doc = contractions.fix(doc)\n    # tokenize document\n    tokens = nltk.word_tokenize(doc)\n    #filter stopwords out of document\n    filtered_tokens = [token for token in tokens if token not in stop_words]\n    # re-create document from filtered tokens\n    doc = ' '.join(filtered_tokens)\n    return doc\n\nnormalize_corpus = np.vectorize(normalize_document)\n\nnorm_corpus = normalize_corpus(list(final_df['Final_Tags']))\nlen(norm_corpus)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\ntfidf_matrix = tf.fit_transform(norm_corpus)\ntfidf_matrix.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ndoc_sim = cosine_similarity(tfidf_matrix)\ndoc_sim_df = pd.DataFrame(doc_sim)\ndoc_sim_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_list = final_df['title'].values\nmovies_list, movies_list.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_list[0:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find Top Similar Movies for a Sample Movie\n#### Let's take the most popular movie \"Apollo 13\" in the dataframe above and try and find the most similar movies which can be recommended\n\n","metadata":{}},{"cell_type":"code","source":"movie_idx = np.where(movies_list == 'Thor')[0][0]\nmovie_idx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc_sim_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_similarities = doc_sim_df.iloc[movie_idx].values\nmovie_similarities\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_movie_idxs = np.argsort(-movie_similarities)[1:11]\nsimilar_movie_idxs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_movies = movies_list[similar_movie_idxs]\nsimilar_movies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df,num=11):\n    # find movie id\n    movie_idx = np.where(movies == movie_title)[0][0]\n    # get movie similarities\n    movie_similarities = doc_sims.iloc[movie_idx].values\n    # get top 5 similar movie IDs\n    similar_movie_idxs = np.argsort(-movie_similarities)[1:num]\n    # get top 5 movies\n    similar_movies = movies[similar_movie_idxs]\n    # return the top 5 movies\n    return similar_movies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get popular Movie Recommendations\n","metadata":{}},{"cell_type":"code","source":"final_df[final_df[\"year\"]==\"2011\"].iloc[0:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"popular_movies = ['How to Train Your Dragon 2','Man of Steel','Lucy' ,'Thor', 'Hunger Games: Catching Fire, The','Super 8','Wolf of Wall Street, The',\n                  'World War Z','Frozen','Now You See Me']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for movie in popular_movies:\n    print('Movie:', movie)\n    recommends = movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df)\n    for fold, i in enumerate(recommends):\n        print('Top',str(fold+1),'recommended Movies : '+ str(i))\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Movie Recommendation with Embeddings(Better Results)","metadata":{}},{"cell_type":"code","source":"from gensim.models import FastText\ntokenized_docs = [doc.split() for doc in norm_corpus]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ft_model = FastText(tokenized_docs, size=100, window=10, min_count=2, workers=1, sg=1, iter=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def averaged_word2vec_vectorizer(corpus, model, num_features):\n    vocabulary = set(model.wv.index2word)\n    \n    def average_word_vectors(words, model, vocabulary, num_features):\n        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n        nwords = 0.\n        \n        for word in words:\n            if word in vocabulary: \n                nwords = nwords + 1.\n                feature_vector = np.add(feature_vector, model.wv[word])\n        if nwords:\n            feature_vector = np.divide(feature_vector, nwords)\n\n        return feature_vector\n\n    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n                    for tokenized_sentence in corpus]\n    return np.array(features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc_vecs_ft = averaged_word2vec_vectorizer(tokenized_docs, ft_model, 100)\ndoc_vecs_ft.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Movie Recommendations","metadata":{}},{"cell_type":"code","source":"doc_sim = cosine_similarity(doc_vecs_ft)\ndoc_sim_df = pd.DataFrame(doc_sim)\ndoc_sim_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for movie in popular_movies:\n    print('Movie:', movie)\n    recommends = movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df)\n    for fold, i in enumerate(recommends):\n        print('Top',str(fold+1),'recommended Movies : '+ str(i))\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}